{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import csv\n",
    "import concurrent.futures\n",
    "from multiprocessing import freeze_support\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "seed = 6969\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "replays_dir = pathlib.Path(\"replays\")\n",
    "leaderboards_dir = pathlib.Path(\"leaderboards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_segment_size = 3\n",
    "post_segment_size = 3\n",
    "prediction_size = 3\n",
    "segment_size = pre_segment_size + post_segment_size + prediction_size\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_leaderboard_replays():\n",
    "  leaderboard_ids = np.array(tf.io.gfile.listdir(str(replays_dir)))\n",
    "  random.shuffle(leaderboard_ids)\n",
    "  val_leaderboard_ids = leaderboard_ids[:int(len(leaderboard_ids)*0.2)]\n",
    "\n",
    "  train_data = []\n",
    "  val_data = []\n",
    "  for leaderboard_id in leaderboard_ids:\n",
    "    replay_files = glob.glob(f'{replays_dir}/{leaderboard_id}/*.json')\n",
    "\n",
    "    if leaderboard_id in val_leaderboard_ids:\n",
    "      val_data.append((leaderboard_id, replay_files))\n",
    "    else:\n",
    "      train_data.append((leaderboard_id, replay_files))\n",
    "\n",
    "  return train_data, val_data\n",
    "\n",
    "def read_replay_file(file):\n",
    "  with open(file, \"r\") as f:\n",
    "    file_content = f.read()\n",
    "    json_content = json.loads(file_content)\n",
    "    return json_content\n",
    "\n",
    "def get_replay_notes(replay):\n",
    "  notes = []\n",
    "  \n",
    "  prev_zero_note_time = 0\n",
    "  prev_one_note_time = 0\n",
    "  \n",
    "  for note_info, score, note_time in sorted(replay, key=lambda item: item[2]):\n",
    "    type = note_info[-1]\n",
    "\n",
    "    # TODO: use map data for note positions and timings to not have to exclude misses (misses are registered much later, which messes up the timings)\n",
    "    if score < 1:\n",
    "      continue\n",
    "    \n",
    "    # NOTE: 0-100 score range is rare and often happens for tracking problems that are not important here\n",
    "    # would be good to replace this with acc component only and potentially learn all both acc and swing angles\n",
    "    # but need different format replay files for that\n",
    "    # score = max(0, score - 100)\n",
    "    \n",
    "    delta_to_zero = note_time - prev_zero_note_time\n",
    "    delta_to_one = note_time - prev_one_note_time\n",
    "    \n",
    "    if type == \"0\":\n",
    "      prev_zero_note_time = note_time\n",
    "      note = preprocess_note(score, delta_to_zero, delta_to_one, note_info)\n",
    "      notes.append(note)\n",
    "    if type == \"1\":\n",
    "      prev_one_note_time = note_time\n",
    "      note = preprocess_note(score, delta_to_one, delta_to_zero, note_info)\n",
    "      notes.append(note)\n",
    "  \n",
    "  return notes\n",
    "\n",
    "def preprocess_note(score, delta, delta_other, note_info):\n",
    "  # NOTE: timing increases difficulty not linearly and caps out at ~2 seconds\n",
    "  # no idea if such parameters can be learned by neural networks without adding scaling like I did right here\n",
    "  delta = max(0, 1.5 - delta)\n",
    "  delta_other = max(0, 1.5 - delta_other)\n",
    "\n",
    "  col_number = int(note_info[0])\n",
    "  row_number = int(note_info[1])\n",
    "  direction_number = int(note_info[2])\n",
    "  color = int(note_info[3])\n",
    "  color_arr = [0, 0]\n",
    "  color_arr[color] = 1\n",
    "\n",
    "  col = [0] * 4\n",
    "  row = [0] * 3\n",
    "  row_col = [0] * 4 * 3\n",
    "  direction = [0] * 10\n",
    "  col[col_number] = 1\n",
    "  row[row_number] = 1\n",
    "  row_col[col_number * 3 + row_number] = 1\n",
    "  direction[direction_number] = 1\n",
    "\n",
    "  response = []\n",
    "  \n",
    "  response.extend(row_col)\n",
    "  response.extend(direction)\n",
    "  response.extend(color_arr)\n",
    "  response.extend([\n",
    "    delta,\n",
    "    delta_other,\n",
    "    score\n",
    "  ])\n",
    "  \n",
    "  return response\n",
    "\n",
    "def create_segments(notes):\n",
    "  if len(notes) < segment_size:\n",
    "    return [], [], [], []\n",
    "  \n",
    "  pre_segments = []\n",
    "  segments = []\n",
    "  post_segments = []\n",
    "  scores = []\n",
    "  for i in range(len(notes) - segment_size):\n",
    "    if i % prediction_size != 0:\n",
    "      continue\n",
    "    \n",
    "    pre_slice = notes[i:i+pre_segment_size]\n",
    "    slice = notes[i+pre_segment_size:i+pre_segment_size+prediction_size]\n",
    "    post_slice = notes[i+pre_segment_size+prediction_size:i+segment_size]\n",
    "\n",
    "    # NOTE: using relative score can be good to find relative difficulty of the notes more fairly\n",
    "    # because good players will always get higher acc and worse players will do badly even on easy patterns\n",
    "\n",
    "    pre_segment = [np.array(note[:-1]) for note in pre_slice]\n",
    "    segment = [np.array(note[:-1]) for note in slice]\n",
    "    post_segment = [np.array(note[:-1]) for note in post_slice]\n",
    "\n",
    "    score = sum([note[-1]/15 for note in slice])/len(slice)\n",
    "\n",
    "    pre_segments.append(pre_segment)\n",
    "    segments.append(segment)\n",
    "    post_segments.append(post_segment)\n",
    "    scores.append(score)\n",
    "    \n",
    "  return pre_segments, segments, post_segments, scores\n",
    "\n",
    "def preprocess_leaderboard_replays(leaderboard_replays, print_progress=False):\n",
    "  asd = []\n",
    "  count = 0\n",
    "  skip = False\n",
    "  \n",
    "  replays = []\n",
    "  \n",
    "  for leaderboard_replay in leaderboard_replays:\n",
    "    replays.append(read_replay_file(leaderboard_replay))\n",
    "    \n",
    "  replays.sort(key=lambda replay: replay[\"totalScore\"], reverse=True)\n",
    "  \n",
    "  for replay in replays:\n",
    "    \n",
    "    note_infos = replay[\"noteInfos\"]\n",
    "    scores = replay[\"scores\"]\n",
    "    note_times = replay[\"noteTime\"]\n",
    "\n",
    "    if(count > 10):\n",
    "      break\n",
    "    \n",
    "    if len(asd) == 0:\n",
    "      asd = []\n",
    "      for values in zip(note_infos, scores, note_times):\n",
    "        if len(values[0]) > 4 or values[1] < -3:\n",
    "          continue\n",
    "        if values[1] <= 0:\n",
    "          asd.append([values[0], [], 0, 0])\n",
    "        else:\n",
    "          asd.append([values[0], [max(0, values[1] - 100)], values[2], 1])\n",
    "    else:\n",
    "      indexes = {}\n",
    "      num_elements = 0\n",
    "      for values in zip(note_infos, scores, note_times):\n",
    "        if len(values[0]) > 4 or values[1] < -3:\n",
    "          continue\n",
    "        \n",
    "        num_elements += 1\n",
    "        if values[0] in indexes:\n",
    "          indexes[values[0]].append([values[0], values[1], values[2]])\n",
    "        else:\n",
    "          indexes[values[0]] = [[values[0], values[1], values[2]]]\n",
    "\n",
    "\n",
    "      if num_elements < len(asd):\n",
    "        continue\n",
    "      try:\n",
    "        for values in asd:\n",
    "          info = indexes[values[0]].pop(0)\n",
    "\n",
    "          if info[1] > 0:\n",
    "            values[1].append(max(0, info[1] - 100))\n",
    "            values[2] += info[2]\n",
    "            values[3] += 1\n",
    "      except:\n",
    "        skip = True\n",
    "        break\n",
    "      \n",
    "    count += 1\n",
    "\n",
    "  if skip:\n",
    "    return [], [], [], []\n",
    "  \n",
    "  if count < 4 and print_progress == True:\n",
    "    return [], [], [], []\n",
    "  \n",
    "  if count < 2 and print_progress == False:\n",
    "    return [], [], [], []\n",
    "  \n",
    "  asd2 = []\n",
    "  for values in asd:\n",
    "    if values[3] == 0:\n",
    "      continue\n",
    "    values[1].sort(reverse=True)\n",
    "    top_acc = values[1]\n",
    "    # top_acc = values[1][1:-1]\n",
    "    acc = sum(top_acc)/len(top_acc) if len(top_acc) > 0 else 0\n",
    "    values[2] = values[2]/values[3]\n",
    "    asd2.append([values[0], acc, values[2]])\n",
    "  \n",
    "  notes = get_replay_notes(asd2)\n",
    "  return create_segments(notes)\n",
    "\n",
    "\n",
    "def generate_data(leaderboards_replays):\n",
    "  pre_segments = []\n",
    "  segments = []\n",
    "  post_segments = []\n",
    "  scores = []\n",
    "  \n",
    "  for leaderboard_replays in leaderboards_replays:\n",
    "    pre_segment, segment, post_segment, score = preprocess_leaderboard_replays(leaderboard_replays)\n",
    "    pre_segments.extend(pre_segment)\n",
    "    segments.extend(segment)\n",
    "    post_segments.extend(post_segment)\n",
    "    scores.extend(score)\n",
    "  \n",
    "  return [np.array(pre_segments), np.array(segments), np.array(post_segments)], np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = get_leaderboard_replays()\n",
    "test_data = val_data\n",
    "\n",
    "train_x, train_y = generate_data(train_data)\n",
    "val_x, val_y = generate_data(val_data)\n",
    "note_size = 26\n",
    "\n",
    "pre_input = keras.Input(shape=(pre_segment_size, note_size), dtype=\"float32\")\n",
    "pre_layer = layers.Flatten()(pre_input)\n",
    "pre_layer = layers.Dense(32, activation=\"relu\")(pre_layer)\n",
    "pre_layer = layers.Dense(32, activation=\"relu\")(pre_layer)\n",
    "input = keras.Input(shape=(prediction_size, note_size), dtype=\"float32\")\n",
    "layer = layers.Flatten()(input)\n",
    "layer = layers.Dense(32, activation=\"relu\")(layer)\n",
    "layer = layers.Dense(32, activation=\"relu\")(layer)\n",
    "post_input = keras.Input(shape=(post_segment_size, note_size), dtype=\"float32\")\n",
    "post_layer = layers.Flatten()(post_input)\n",
    "post_layer = layers.Dense(32, activation=\"relu\")(post_layer)\n",
    "post_layer = layers.Dense(32, activation=\"relu\")(post_layer)\n",
    "  \n",
    "inputs = [pre_input, input, post_input]\n",
    "layers2 = [pre_layer, layer, post_layer]\n",
    "l = layers.Concatenate()(layers2)\n",
    "l = layers.Flatten()(l)\n",
    "l = layers.Dense(64, activation=\"relu\")(l)\n",
    "l = layers.Dense(64, activation=\"relu\")(l)\n",
    "out = layers.Dense(1, activation=\"linear\")(l)\n",
    "model = models.Model(inputs=inputs, outputs = out)\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "    loss=tf.keras.losses.MeanAbsoluteError(reduction=\"sum_over_batch_size\"),\n",
    "    metrics=['mae', 'mse'],\n",
    ")\n",
    "\n",
    "tot = 0\n",
    "for score in train_y:\n",
    "    tot += score\n",
    "avg = tot/len(train_y)\n",
    "totdiff = 0\n",
    "\n",
    "for score in train_y:\n",
    "    totdiff += max(score - avg, avg - score)\n",
    "avgdiff = totdiff/len(train_y)\n",
    "\n",
    "print(f\"Average value: {avg}\")\n",
    "print(f\"Average diff: {avgdiff}\")\n",
    "\n",
    "totdiff = 0\n",
    "for score in val_y:\n",
    "    totdiff += max(score - avg, avg - score)\n",
    "avgdiff = totdiff/len(val_y)\n",
    "print(f\"Average diff: {avgdiff}\")\n",
    "  \n",
    "log_dir = \"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir, histogram_freq = 1)\n",
    "  \n",
    "history = model.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    validation_data=(val_x, val_y),\n",
    "    batch_size=batch_size,\n",
    "    epochs=10,\n",
    "    shuffle=True,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(verbose=1, patience=20), tensorboard_callback]\n",
    ")\n",
    "\n",
    "predictions = []\n",
    "for leaderboard_id, leaderboard_replays in test_data:\n",
    "    try:\n",
    "      pre, curr, post, score = preprocess_leaderboard_replays(leaderboard_replays)\n",
    "\n",
    "      _predictions = model.predict([np.array(pre), np.array(curr), np.array(post)])\n",
    "\n",
    "      real_sum = 0\n",
    "      for prediction in score:\n",
    "        real_sum += prediction\n",
    "\n",
    "      real_avg = real_sum/_predictions.size\n",
    "      real_percentage_score = (real_avg*15+100)/115\n",
    "\n",
    "      prediction_sum = 0\n",
    "      for prediction in _predictions:\n",
    "        prediction_sum += prediction[0]\n",
    "\n",
    "      avg = prediction_sum/_predictions.size\n",
    "      percentage_score = (avg*15+100)/115\n",
    "\n",
    "      predictions.append([f\"https://scoresaber.com/leaderboard/{leaderboard_id}\", round(percentage_score, 5), round(real_percentage_score, 5), abs(round(real_percentage_score - percentage_score, 5))])\n",
    "    except KeyboardInterrupt:\n",
    "      raise\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "      continue\n",
    "with open('predictions.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "      writer = csv.writer(f)\n",
    "      header = [\"LeaderboardId\", \"Prediction\", \"Expected\", \"Difference\"]\n",
    "      writer.writerow(header)\n",
    "\n",
    "      for prediction in predictions:\n",
    "        writer.writerow(prediction)\n",
    "\n",
    "\n",
    "model.save('model_sleep')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
